{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ba3b1a-408f-4725-9365-772d3ff57ad2",
   "metadata": {},
   "source": [
    "# Evaluation of DevAssistant\n",
    "\n",
    "This notebook act as a guide to evaluate the performance of the Large Language Model (LLM) powered chatbot (here called DevAssistant) designed to answer documentation related queries. After a initial setup, first section relates to prompt engineering, in which we evaluate the prompts of the model and test queries with a different prompt. Then, we have a retriever evaluation section, in which we can assess the embedding models and similarity search algorithms, investigating differences between text embeddings and other vector store related parameters (such as chunk size or k-similarity). The final section relates to response evaluation, measuring if the final response of the LLM is faithful to the context retrieved and also relevant to user query.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e23815-08c3-492d-88c6-0f5c6850efba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/jovyan/work/loka_challenge/challenge\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: chromadb<0.5.0,>=0.4.24 in /opt/conda/lib/python3.10/site-packages (from challenge==0.1.0) (0.4.24)\n",
      "Requirement already satisfied: llama-index<0.11.0,>=0.10.30 in /opt/conda/lib/python3.10/site-packages (from challenge==0.1.0) (0.10.30)\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from challenge==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: llama-index-llms-ollama<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from challenge==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: llama-index-vector-stores-chroma<0.2.0,>=0.1.6 in /opt/conda/lib/python3.10/site-packages (from challenge==0.1.0) (0.1.6)\n",
      "Requirement already satisfied: ollama<0.2.0,>=0.1.8 in /opt/conda/lib/python3.10/site-packages (from challenge==0.1.0) (0.1.8)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from challenge==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: slack-bolt<2.0.0,>=1.18.1 in /opt/conda/lib/python3.10/site-packages (from challenge==0.1.0) (1.18.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.28 in /home/jovyan/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/jovyan/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.4.2)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/jovyan/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.110.1)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.29.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/jovyan/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.23.5)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/jovyan/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (4.8.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.24.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/jovyan/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (5.8.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.62.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.9.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (29.0.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/jovyan/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (6.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /opt/conda/lib/python3.10/site-packages (from chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (3.10.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.2.2)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.12)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.30 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.10.30)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.8)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.5)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.16)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.5)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.5)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.19)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /opt/conda/lib/python3.10/site-packages (from llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /home/jovyan/.local/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (0.22.2)\n",
      "Requirement already satisfied: sentence-transformers<3.0.0,>=2.6.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (2.7.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from ollama<0.2.0,>=0.1.8->challenge==0.1.0) (0.27.0)\n",
      "Requirement already satisfied: slack-sdk<4,>=3.25.0 in /opt/conda/lib/python3.10/site-packages (from slack-bolt<2.0.0,>=1.18.1->challenge==0.1.0) (3.27.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /home/jovyan/.local/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.0.1)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.37.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<0.2.0,>=0.1.8->challenge==0.1.0) (3.6.1)\n",
      "Requirement already satisfied: certifi in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<0.2.0,>=0.1.8->challenge==0.1.0) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<0.2.0,>=0.1.8->challenge==0.1.0) (1.0.5)\n",
      "Requirement already satisfied: idna in /home/jovyan/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<0.2.0,>=0.1.8->challenge==0.1.0) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama<0.2.0,>=0.1.8->challenge==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<0.2.0,>=0.1.8->challenge==0.1.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (3.13.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (3.9.3)\n",
      "Requirement already satisfied: minijinja>=1.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (1.0.16)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/jovyan/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/jovyan/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.9.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/jovyan/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.6.4)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/jovyan/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /home/jovyan/.local/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.0.7)\n",
      "Requirement already satisfied: openai>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (1.14.3)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/jovyan/.local/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (2.0.23)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/jovyan/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (1.0.8)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.1.18)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/jovyan/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (3.8.1)\n",
      "Requirement already satisfied: pandas in /home/jovyan/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (10.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/jovyan/.local/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (4.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (0.4.1)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (4.25.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.10.1)\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (6.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.45b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/jovyan/.local/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (68.2.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jovyan/.local/lib/python3.10/site-packages (from requests>=2.28->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (3.3.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (4.40.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (1.12.0+cu116)\n",
      "Requirement already satisfied: scikit-learn in /home/jovyan/.local/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (1.2.2)\n",
      "Requirement already satisfied: scipy in /home/jovyan/.local/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (1.10.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (8.1.7)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (12.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jovyan/.local/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (4.0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (2.3.2.post1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jovyan/.local/lib/python3.10/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (3.17.0)\n",
      "Requirement already satisfied: joblib in /home/jovyan/.local/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (1.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jovyan/.local/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (3.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (0.4.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (3.21.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jovyan/.local/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.30->llama-index<0.11.0,>=0.10.30->challenge==0.1.0) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jovyan/.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface<0.3.0,>=0.2.0->challenge==0.1.0) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (1.2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.24->challenge==0.1.0) (0.4.8)\n",
      "Building wheels for collected packages: challenge\n",
      "  Building editable for challenge (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for challenge: filename=challenge-0.1.0-py3-none-any.whl size=2900 sha256=42364595c8e0762e8567d73eb4dc74edcf574a107f223cd5fbfb5267a68c8057\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-j3orcl0_/wheels/ea/d2/0e/bb304a0304a996fb7c40475aa1aadb6c3ce208cd422cb80b7a\n",
      "Successfully built challenge\n",
      "Installing collected packages: challenge\n",
      "  Attempting uninstall: challenge\n",
      "    Found existing installation: challenge 0.1.0\n",
      "    Uninstalling challenge-0.1.0:\n",
      "      Successfully uninstalled challenge-0.1.0\n",
      "Successfully installed challenge-0.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513553eb-500a-4bec-9342-47a7184d79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio \n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e61a539-6059-4cdd-b9c7-3a3479fde766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/jovyan/.local/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import challenge.rag as rag\n",
    "import challenge.vector_store as vs\n",
    "import challenge.models as models\n",
    "\n",
    "from llama_index.core import Settings\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eeccf60-ff36-4ded-8099-f81d2715a7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb20978-9584-409e-ab53-f1bf55f5c80e",
   "metadata": {},
   "source": [
    "Here, as an example for this evaluation guide, we use ``Flag Embedding`` as the embedding model and ``llama3`` as the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca542f4-6125-4e39-a044-a211f8bfb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = models.embeddingModels('flagembedding')\n",
    "llm = models.LLMs('GPT-3')\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b640db5-9b41-469e-98fd-1b8c9b201754",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = vs.ChromaVS()\n",
    "\n",
    "query_engine_builder = rag.QueryEngine(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f02973-9dcd-4371-a5b0-c0733cc4ac33",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prompt Engineering\n",
    "\n",
    "In this section we assess the default prompt from ``llama_index`` and manually creates a new one, to be more specific to the task at hand. We evaluates both prompts by the following queries:\n",
    "- What is Sagemaker?\n",
    "- How to check if an endpoint is KMS encrypted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da095fe-8af0-48f3-84a5-e9f82582b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define prompt viewing function (as per llama_index docs)\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c257aaee-70a8-4704-b26e-9329bf63e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection exists\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Default prompt for query engine\n",
    "query_engine = query_engine_builder.buildQueryEngine()\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f585e4a8-3184-42f0-9f4c-e597c56bada2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sagemaker is a fully managed machine learning service that allows data scientists and developers to build, train, and deploy machine learning models easily. It provides an integrated Jupyter authoring notebook instance for data exploration and analysis without the need to manage servers. Additionally, Sagemaker allows for the association of Git repositories with Jupyter notebook instances to save notebooks in a source control environment, and it enables the management of private repository credentials using Secrets Manager.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query('What is Sagemaker').response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d12e525-844f-4382-9a39-35812ad45a52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To check if an endpoint is KMS encrypted, you need to verify the `KmsKeyId` property associated with the endpoint. If the `KmsKeyId` property is specified with a valid AWS Key Management Service (KMS) key ARN, it indicates that the endpoint is KMS encrypted. This key is used to encrypt the data at rest using Amazon S3 server-side encryption.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query('How to check if an endpoint is KMS encrypted?').response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1d80d9b-1173-4ac3-9c5d-60cd37215935",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_query_eng_str = \"\"\"\n",
    "You are an expert Q&A slack bot assistant, designed to answer questions about a specific documentation.\n",
    "Some rules below:\n",
    "1 - Always reference the context information and link documentation for further knowledge\n",
    "2 - Use three sentences maximum\n",
    "3 - Keep the answer concise.\n",
    "4 - If you don't know the answer, politely say that you don't know.\n",
    "Documentation is below.\n",
    "-----------------------\n",
    "{context_str}\n",
    "-----------------------\n",
    "Given the documentation and not prior knowledge, answer the query:\n",
    "Query: {query_str}\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa921cb1-95c2-4c60-9256-898235904a19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine_builder.addPromptTemplate(prompt_query_eng_str)\n",
    "query_engine = query_engine_builder.query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740d30b0-7880-4cdb-8298-9fa4c01b4c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert Q&A slack bot assistant, designed to answer questions about a specific documentation.\n",
      "Some rules below:\n",
      "1 - Always reference the context information and link documentation for further knowledge\n",
      "2 - Use three sentences maximum\n",
      "3 - Keep the answer concise.\n",
      "4 - If you don't know the answer, politely say that you don't know.\n",
      "Documentation is below.\n",
      "-----------------------\n",
      "{context_str}\n",
      "-----------------------\n",
      "Given the documentation and not prior knowledge, answer the query:\n",
      "Query: {query_str}\n",
      "Answer:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d978456f-51ec-40a4-a1cb-557a9a428085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazon SageMaker is a fully managed machine learning service that allows data scientists and developers to build, train, and deploy machine learning models easily. It provides an integrated Jupyter authoring notebook instance for data exploration and analysis without the need to manage servers. You can also associate Git repositories with your Jupyter notebook instances and manage private repository credentials using AWS Secrets Manager. For more information, you can refer to the documentation on integrating SageMaker.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query('What is Sagemaker').response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d002a31-332c-4c99-b03e-f029e10b60f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To check if an endpoint is KMS encrypted, you can look for the `KmsKeyId` property in the documentation of the specific service or resource, such as SageMaker Feature Store or SageMaker Monitoring Schedule. This property will specify the AWS Key Management Service (KMS) key used for encryption. You can also verify the permissions required for the KMS key to ensure proper encryption and access control. For more detailed information, refer to the documentation for the specific service or resource.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query('How to check if an endpoint is KMS encrypted?').response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622851e-2853-44de-99e4-c46eb0066c13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retriever Evaluation\n",
    "\n",
    "This section evaluates the retriever algorithm, which is responsible for retrieving the documents from the vector database. As the retriever searches the information in an embedded space, evaluating it can help us in choosing the best embedding model. Evaluating the retriever can also give us insights about best choices of K and chunk size parameters. Here, as an example, we evaluate the retrieval information for the same two queries:\n",
    "- What is Sagemaker?\n",
    "- How to check if an endpoint is KMS encrypted?\n",
    "\n",
    "We also created a guide for batch evaluating synthetic dataset. In this part, we generate query-chunk pairs from the documentation using a 'gold' LLM, and then assess the retriever performance in those pairs with Mean Reciprocal Rank (MRR) and Hit Rate metrics (i.e. measuring if the retriver finds the correct chunks from the documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ae239fb-0ae5-4e6e-985c-45ba224f7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = vector_store.index\n",
    "retriever = index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a9465d-4daf-46f6-995f-b19aca35acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = retriever.retrieve('What is SageMaker?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1ee3c2-2358-4211-9122-57f6aebc07ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 618b0f23-1d60-4428-a8b2-182d9179a5f5<br>**Similarity:** 0.6162639987868705<br>**Text:** How Amazon SageMaker uses AWS Secrets Manager<a name=\"integrating-sagemaker\"></a>\n",
       "\n",
       "SageMaker is a fully managed machine learning service\\. With SageMaker, data scientists and developers can quickly and easily build and train machine learning models, and then directly deploy them into a production\\-ready hosted environment\\. It provides an integrated Jupyter authoring notebook instance for easy access to your data sources for exploration and analysis, so you don't have to manage servers\\. \n",
       "\n",
       "You can associate Git repositories with your Jupyter notebook instances to save your notebooks in a source control environment that persists even if you stop or delete your notebook instance\\. You can manage your private repositories credentials using Secrets Manager\\. For more information, see Associate Git Repositories with Amazon SageMaker Notebook Instances in the *Amazon SageMaker Developer Guide*\\.\n",
       "\n",
       "To import data from Databricks, Data Wrangler stores your JDBC URL in Secrets Manager\\. For m...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** b55bceef-fa01-410f-b717-7c345ec31612<br>**Similarity:** 0.6095380781756486<br>**Text:** Working with Amazon SageMaker<a name=\"examples-sagemaker\"></a>\n",
       "\n",
       " Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning \\(ML\\) models\\. See the following resources for complete code examples with instructions\\.\n",
       "\n",
       " Link to Github \n",
       "\n",
       " Link to AWS Code Sample Catalog<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    display_source_node(node, source_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "167b1d46-b652-4907-ab29-1b7819f59e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = retriever.retrieve('How to check if an endpoint is KMS encrypted?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c30adf6e-1339-40ab-8698-0888b9ecd19b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 5b1ad9d5-a66c-4a8f-8f1a-322d0a7c9523<br>**Similarity:** 0.5948779343132263<br>**Text:** Properties<a name=\"aws-properties-sagemaker-monitoringschedule-monitoringoutputconfig-properties\"></a>\n",
       "\n",
       "`KmsKeyId`  \n",
       "The AWS Key Management Service \\(AWS KMS\\) key that Amazon SageMaker uses to encrypt the model artifacts at rest using Amazon S3 server\\-side encryption\\.  \n",
       "*Required*: No  \n",
       "*Type*: String  \n",
       "*Maximum*: `2048`  \n",
       "*Pattern*: `.*`  \n",
       "*Update requires*: No interruption\n",
       "\n",
       "`MonitoringOutputs`  \n",
       "Monitoring outputs for monitoring jobs\\. This is where the output of the periodic monitoring jobs is uploaded\\.  \n",
       "*Required*: Yes  \n",
       "*Type*: List of MonitoringOutput  \n",
       "*Maximum*: `1`  \n",
       "*Update requires*: No interruption<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Node ID:** f31b4633-176e-406d-9a6b-1886c332e58b<br>**Similarity:** 0.5932938917945147<br>**Text:** Properties<a name=\"aws-properties-sagemaker-featuregroup-onlinestoresecurityconfig-properties\"></a>\n",
       "\n",
       "`KmsKeyId`  \n",
       "The AWS Key Management Service \\(KMS\\) key ARN that SageMaker Feature Store uses to encrypt the Amazon S3 objects at rest using Amazon S3 server\\-side encryption\\.  \n",
       "The caller \\(either user or IAM role\\) of `CreateFeatureGroup` must have below permissions to the `OnlineStore` `KmsKeyId`:  \n",
       "+  `\"kms:Encrypt\"` \n",
       "+  `\"kms:Decrypt\"` \n",
       "+  `\"kms:DescribeKey\"` \n",
       "+  `\"kms:CreateGrant\"` \n",
       "+  `\"kms:RetireGrant\"` \n",
       "+  `\"kms:ReEncryptFrom\"` \n",
       "+  `\"kms:ReEncryptTo\"` \n",
       "+  `\"kms:GenerateDataKey\"` \n",
       "+  `\"kms:ListAliases\"` \n",
       "+  `\"kms:ListGrants\"` \n",
       "+  `\"kms:RevokeGrant\"` \n",
       "The caller \\(either user or IAM role\\) to all DataPlane operations \\(`PutRecord`, `GetRecord`, `DeleteRecord`\\) must have the following permissions to the `KmsKeyId`:  \n",
       "+  `\"kms:Decrypt\"` \n",
       "*Required*: No  \n",
       "*Type*: String  \n",
       "*Maximum*: `2048`  \n",
       "*Pattern*: `.*`  \n",
       "*Update requires*: Replacement<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for node in retrieved_nodes:\n",
    "    display_source_node(node, source_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7511a8-5c33-4dd0-885c-5927762515d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Generating synthetic dataset for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcb144b3-761b-43ab-b7a0-4b26f85a3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "documents = vector_store.getDocuments()\n",
    "node_parser = SentenceSplitter(chunk_size=512)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)\n",
    "\n",
    "# by default, the node ids are set to random uuids. To ensure same id's per run, we manually set them.\n",
    "for idx, node in enumerate(nodes):\n",
    "    node.id_ = f\"node_{idx}\"\n",
    "    \n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "retriever = vector_index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f21b100-b41f-493c-9e24-cf8d98edb48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 10/10 [00:16<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "\n",
    "qa_dataset = generate_question_context_pairs(\n",
    "    nodes[:10], llm=llm, num_questions_per_chunk=2\n",
    ")\n",
    "qa_dataset.save_json(\"pg_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0fb7be-77aa-4cd9-9f84-8a927660228c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36524f2f-be3c-4056-a3fe-db064d6a69f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does the SageMaker Training and SageMaker Inference toolkits help users adapt their containers to run scripts, train algorithms, and deploy models on SageMaker?\n"
     ]
    }
   ],
   "source": [
    "queries = qa_dataset.queries.values()\n",
    "print(list(queries)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b9b33b0-59be-4fd3-b9d1-88a284b04a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "metrics = [\"mrr\", \"hit_rate\"]\n",
    "\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b956787-ca8e-485e-8719-115bc0b29f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "601a4db1-d3b0-4e2a-b37b-59b74e2d4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate:  0.7\n",
      "MRR:  0.675\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metric_dicts = []\n",
    "for eval_result in eval_results:\n",
    "    metric_dict = eval_result.metric_vals_dict\n",
    "    metric_dicts.append(metric_dict)\n",
    "    \n",
    "metrics_df = pd.DataFrame(metric_dicts)\n",
    "hit_rate = metrics_df['hit_rate'].mean()\n",
    "mrr = metrics_df['mrr'].mean()\n",
    "print('Hit Rate: ', hit_rate)\n",
    "print('MRR: ', mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe797f-05df-4528-8bd1-97451159b5d0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Response Evaluation\n",
    "\n",
    "This section evaluates the response algorithm, which is responsible for the generated final answer. Evaluating the response can help us choosing the best LLM model for our task. It also works as an overall assessment of the system, measuring its faithfulness and relevancy. We evaluate the response with the same two queries:\n",
    "- What is Sagemaker?\n",
    "- How to check if an endpoint is KMS encrypted?\n",
    "\n",
    "As in the retriever section, we created a guide for batch evaluating synthetic dataset. In this part, we generate questions from the documentation with an LLM and then measure the faithfulness and relevance of the response using a 'gold' LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a800c7fc-256c-4b64-932c-a237d0e255c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/jovyan/.local/lib/python3.10/site-packages (from spacy) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/jovyan/.local/lib/python3.10/site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/jovyan/.local/lib/python3.10/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/jovyan/.local/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/jovyan/.local/lib/python3.10/site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/jovyan/.local/lib/python3.10/site-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/jovyan/.local/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/jovyan/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jovyan/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jovyan/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jovyan/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jovyan/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ea47b02-e43b-4e63-8230-6db9b9e195c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is Sagemaker?'\n",
    "response = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2617afbb-f3ea-4e34-a2b3-75cf624d68aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(query=None, contexts=['How Amazon SageMaker uses AWS Secrets Manager<a name=\"integrating-sagemaker\"></a>\\n\\nSageMaker is a fully managed machine learning service\\\\. With SageMaker, data scientists and developers can quickly and easily build and train machine learning models, and then directly deploy them into a production\\\\-ready hosted environment\\\\. It provides an integrated Jupyter authoring notebook instance for easy access to your data sources for exploration and analysis, so you don\\'t have to manage servers\\\\. \\n\\nYou can associate Git repositories with your Jupyter notebook instances to save your notebooks in a source control environment that persists even if you stop or delete your notebook instance\\\\. You can manage your private repositories credentials using Secrets Manager\\\\. For more information, see Associate Git Repositories with Amazon SageMaker Notebook Instances in the *Amazon SageMaker Developer Guide*\\\\.\\n\\nTo import data from Databricks, Data Wrangler stores your JDBC URL in Secrets Manager\\\\. For more information, see Import data from Databricks \\\\(JDBC\\\\)\\\\.\\n\\nTo import data from Snowflake, Data Wrangler stores your credentials in a Secrets Manager secret\\\\. For more information, see Import data from Snowflake\\\\.', 'Working with Amazon SageMaker<a name=\"examples-sagemaker\"></a>\\n\\n Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning \\\\(ML\\\\) models\\\\. See the following resources for complete code examples with instructions\\\\.\\n\\n Link to Github \\n\\n Link to AWS Code Sample Catalog'], response='Amazon SageMaker is a fully managed machine learning service that allows data scientists and developers to build, train, and deploy machine learning models easily. It provides an integrated Jupyter authoring notebook instance for data exploration and analysis without the need to manage servers. For more information, you can refer to the documentation on integrating SageMaker [here](/home/jovyan/work/loka_challenge/challenge/tests/../data/sagemaker_documentation/integrating-sagemaker.md).', passing=True, feedback='YES', score=1.0, pairwise_source=None, invalid_result=False, invalid_reason=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "\n",
    "evaluator = FaithfulnessEvaluator(llm = llm)\n",
    "eval_result = evaluator.evaluate_response(response = response)\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02a18cdd-d528-4f97-b3bf-8664bb5bc4de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationResult(query='What is Sagemaker?', contexts=['How Amazon SageMaker uses AWS Secrets Manager<a name=\"integrating-sagemaker\"></a>\\n\\nSageMaker is a fully managed machine learning service\\\\. With SageMaker, data scientists and developers can quickly and easily build and train machine learning models, and then directly deploy them into a production\\\\-ready hosted environment\\\\. It provides an integrated Jupyter authoring notebook instance for easy access to your data sources for exploration and analysis, so you don\\'t have to manage servers\\\\. \\n\\nYou can associate Git repositories with your Jupyter notebook instances to save your notebooks in a source control environment that persists even if you stop or delete your notebook instance\\\\. You can manage your private repositories credentials using Secrets Manager\\\\. For more information, see Associate Git Repositories with Amazon SageMaker Notebook Instances in the *Amazon SageMaker Developer Guide*\\\\.\\n\\nTo import data from Databricks, Data Wrangler stores your JDBC URL in Secrets Manager\\\\. For more information, see Import data from Databricks \\\\(JDBC\\\\)\\\\.\\n\\nTo import data from Snowflake, Data Wrangler stores your credentials in a Secrets Manager secret\\\\. For more information, see Import data from Snowflake\\\\.', 'Working with Amazon SageMaker<a name=\"examples-sagemaker\"></a>\\n\\n Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning \\\\(ML\\\\) models\\\\. See the following resources for complete code examples with instructions\\\\.\\n\\n Link to Github \\n\\n Link to AWS Code Sample Catalog'], response='Amazon SageMaker is a fully managed machine learning service that allows data scientists and developers to build, train, and deploy machine learning models easily. It provides an integrated Jupyter authoring notebook instance for data exploration and analysis without the need to manage servers. For more information, you can refer to the documentation on integrating SageMaker [here](/home/jovyan/work/loka_challenge/challenge/tests/../data/sagemaker_documentation/integrating-sagemaker.md).', passing=True, feedback='YES', score=1.0, pairwise_source=None, invalid_result=False, invalid_reason=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.evaluation import RelevancyEvaluator\n",
    "\n",
    "evaluator = RelevancyEvaluator(llm = llm)\n",
    "eval_result = evaluator.evaluate_response(query = query, response = response)\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6f509-a0f0-4cd0-b82f-328393c09512",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating dataset for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4543d5d4-2042-433f-bea6-84e721fb58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating dataset and evaluating\n",
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "\n",
    "async def evaluateRAG(vector_store, llm):\n",
    "    documents = vector_store.getDocuments()\n",
    "    dataset_generator = RagDatasetGenerator.from_documents(\n",
    "        documents=documents,\n",
    "        llm=llm,\n",
    "        num_questions_per_chunk=10,  # set the number of questions per nodes\n",
    "    )\n",
    "\n",
    "    rag_dataset = dataset_generator.generate_questions_from_nodes()\n",
    "    return rag_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e109693a-cb5d-40d6-bfac-367b3278d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = vector_store.getDocuments()[:10]\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "        documents=documents,\n",
    "        llm=llm,\n",
    "        num_questions_per_chunk=10,  # set the number of questions per nodes\n",
    "    )\n",
    "\n",
    "rag_dataset = dataset_generator.generate_questions_from_nodes()\n",
    "questions = [e.query for e in rag_dataset.examples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890d9e7-b143-4164-85c1-6244498e624e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Batch Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93fceb7d-5e0e-41c2-b79c-2e558de6c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import BatchEvalRunner\n",
    "\n",
    "runner = BatchEvalRunner(\n",
    "    {\"faithfulness\": FaithfulnessEvaluator(llm = llm), \"relevancy\": RelevancyEvaluator(llm = llm)},\n",
    "    workers=8,\n",
    ")\n",
    "\n",
    "eval_results = await runner.aevaluate_queries(\n",
    "    query_engine, queries=questions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3fa8556-40d2-459b-9bd3-cac95730902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithfulnes:  0.97\n",
      "Relevancy:  0.83\n"
     ]
    }
   ],
   "source": [
    "faithfulness_scores = []\n",
    "for eval_result in eval_results['faithfulness']:\n",
    "    faithfulness_score = eval_result.score\n",
    "    faithfulness_scores.append(faithfulness_score)\n",
    "faithfulness_df = pd.DataFrame(faithfulness_scores)\n",
    "    \n",
    "relevancy_scores = []\n",
    "for eval_result in eval_results['relevancy']:\n",
    "    relevancy_score = eval_result.score\n",
    "    relevancy_scores.append(relevancy_score)\n",
    "relevancy_df = pd.DataFrame(relevancy_scores)\n",
    "\n",
    "faithfulness = faithfulness_df[0].mean()\n",
    "relevancy = relevancy_df[0].mean()\n",
    "print('Faithfulnes: ', faithfulness)\n",
    "print('Relevancy: ', relevancy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
